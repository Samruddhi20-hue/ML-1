{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['jaundice'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 49\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Select features\u001b[39;00m\n\u001b[0;32m     44\u001b[0m features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA1_Score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA2_Score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA3_Score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA4_Score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA5_Score\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     45\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA6_Score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA7_Score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA8_Score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA9_Score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA10_Score\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     46\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124methnicity\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjaundice\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontry_of_res\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     47\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mused_app_before\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage_group\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 49\u001b[0m X \u001b[38;5;241m=\u001b[39m df[features]\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Split data\u001b[39;00m\n\u001b[0;32m     52\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m     53\u001b[0m     X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, stratify\u001b[38;5;241m=\u001b[39my, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m     54\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ayush\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\ayush\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ayush\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['jaundice'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                            f1_score, roc_auc_score, confusion_matrix, \n",
    "                            RocCurveDisplay, PrecisionRecallDisplay)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline as make_imb_pipeline\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('Autism-Prediction-using-Machine-Learning---DataSet.csv')\n",
    "\n",
    "# Data Cleaning\n",
    "# Replace '?' with NaN and handle missing values\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "\n",
    "# Handle negative values in 'result' column\n",
    "df['result'] = df['result'].apply(lambda x: x if x > 0 else np.nan)\n",
    "\n",
    "# Feature Engineering\n",
    "# Create total score from A1-A10\n",
    "df['total_score'] = df[[f'A{i}_Score' for i in range(1, 11)]].sum(axis=1)\n",
    "\n",
    "# Create age groups\n",
    "df['age_group'] = pd.cut(df['age'], bins=[0, 12, 18, 30, 50, 100],\n",
    "                        labels=['child', 'teen', 'young', 'adult', 'senior'])\n",
    "\n",
    "# Preprocessing\n",
    "# Define target variable (assuming 'austim' is the target)\n",
    "y = df['austim'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "# Select features\n",
    "features = ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score',\n",
    "            'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score',\n",
    "            'age', 'gender', 'ethnicity', 'jaundice', 'contry_of_res',\n",
    "            'used_app_before', 'result', 'relation', 'total_score', 'age_group']\n",
    "\n",
    "X = df[features]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Preprocessing pipeline\n",
    "numeric_features = ['age', 'result', 'total_score']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_features = ['gender', 'ethnicity', 'jaundice', 'contry_of_res',\n",
    "                       'used_app_before', 'relation', 'age_group']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Feature selection and dimensionality reduction\n",
    "feature_selector = SelectKBest(score_func=f_classif, k=15)\n",
    "pca = PCA(n_components=0.95)\n",
    "\n",
    "# Define models\n",
    "xgb_model = xgb.XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "lgbm_model = LGBMClassifier(random_state=42)\n",
    "\n",
    "# Hyperparameter grids\n",
    "param_grid_xgb = {\n",
    "    'classifier__learning_rate': [0.01, 0.1],\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [3, 5],\n",
    "    'classifier__subsample': [0.8, 1.0],\n",
    "    'classifier__colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "param_grid_lgbm = {\n",
    "    'classifier__learning_rate': [0.01, 0.1],\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__num_leaves': [31, 63],\n",
    "    'classifier__feature_fraction': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Create voting classifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', xgb_model),\n",
    "        ('lgbm', lgbm_model)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Full pipeline with SMOTE\n",
    "pipeline = make_imb_pipeline(\n",
    "    preprocessor,\n",
    "    SMOTE(random_state=42),\n",
    "    feature_selector,\n",
    "    pca,\n",
    "    voting_clf\n",
    ")\n",
    "\n",
    "# GridSearchCV setup\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=[\n",
    "        {\n",
    "            'feature_selector__k': [15, 20],\n",
    "            'pca__n_components': [None, 0.95],\n",
    "            'votingclf__xgb__learning_rate': [0.01, 0.1],\n",
    "            'votingclf__xgb__n_estimators': [100, 200]\n",
    "        }\n",
    "    ],\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Train model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "RocCurveDisplay.from_estimator(best_model, X_test, y_test)\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "\n",
    "# Feature Importance (for tree-based models)\n",
    "try:\n",
    "    importances = best_model.named_steps['votingclf'].estimators_[0].feature_importances_\n",
    "    features_names = preprocessor.get_feature_names_out()\n",
    "    selected_features = features_names[feature_selector.get_support()]\n",
    "    importance_df = pd.DataFrame({'Feature': selected_features, 'Importance': importances})\n",
    "    importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='Importance', y='Feature', data=importance_df.head(15))\n",
    "    plt.title('Top 15 Feature Importances')\n",
    "    plt.show()\n",
    "except AttributeError:\n",
    "    print(\"Feature importance not available for selected model configuration\")\n",
    "\n",
    "# Save model\n",
    "import joblib\n",
    "joblib.dump(best_model, 'autism_detection_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
